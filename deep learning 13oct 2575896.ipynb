{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1873bfb3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Build a deep learning model to classify the mnist digits dataset with Batch Normalization.\n",
    "Build a Feed Forward Neural Network for any problems with keras tuner.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db89ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3a0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88614676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to build the model with a specific optimizer\n",
    "def build_model(optimizer):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0be6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with SGD optimizer:\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 49s 51ms/step - loss: 0.1997 - accuracy: 0.9477 - val_loss: 0.0813 - val_accuracy: 0.9791\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 52s 56ms/step - loss: 0.0739 - accuracy: 0.9814 - val_loss: 0.0574 - val_accuracy: 0.9844\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 73s 78ms/step - loss: 0.0530 - accuracy: 0.9867 - val_loss: 0.0465 - val_accuracy: 0.9869\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 71s 75ms/step - loss: 0.0422 - accuracy: 0.9895 - val_loss: 0.0414 - val_accuracy: 0.9881\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 72s 76ms/step - loss: 0.0356 - accuracy: 0.9909 - val_loss: 0.0379 - val_accuracy: 0.9885\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0379 - accuracy: 0.9885\n",
      "Test accuracy with SGD optimizer: 0.9884999990463257\n",
      "\n",
      "Training with ADAM optimizer:\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 71s 74ms/step - loss: 0.1062 - accuracy: 0.9692 - val_loss: 0.0593 - val_accuracy: 0.9815\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 61s 65ms/step - loss: 0.0356 - accuracy: 0.9890 - val_loss: 0.0382 - val_accuracy: 0.9885\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 81s 87ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.0365 - val_accuracy: 0.9889\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 70s 75ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0369 - val_accuracy: 0.9882\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 64s 69ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0373 - val_accuracy: 0.9881\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0373 - accuracy: 0.9881\n",
      "Test accuracy with ADAM optimizer: 0.988099992275238\n",
      "\n",
      "Training with RMSPROP optimizer:\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 80s 75ms/step - loss: 0.0865 - accuracy: 0.9746 - val_loss: 0.0555 - val_accuracy: 0.9821\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.0401 - val_accuracy: 0.9874\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 87s 93ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0330 - val_accuracy: 0.9890\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 90s 96ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0455 - val_accuracy: 0.9856\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 79s 85ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0340 - val_accuracy: 0.9912\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0340 - accuracy: 0.9912\n",
      "Test accuracy with RMSPROP optimizer: 0.9911999702453613\n"
     ]
    }
   ],
   "source": [
    "# List of optimizers to try\n",
    "optimizers = ['sgd', 'adam', 'rmsprop']\n",
    "\n",
    "for optimizer_name in optimizers:\n",
    "    # Build the model with the current optimizer\n",
    "    model = build_model(optimizer_name)\n",
    "    \n",
    "    print(f\"\\nTraining with {optimizer_name.upper()} optimizer:\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "    print(f'Test accuracy with {optimizer_name.upper()} optimizer: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d40f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12582277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09aa3eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_20648\\3405580802.py:6: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ee7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset (example with MNIST for simplicity)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fac26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model building function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Tune the number of layers and units in each layer\n",
    "    for i in range(hp.Int('num_layers', 2, 5)):\n",
    "        model.add(layers.Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
    "                               activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate and optimizer\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c20415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_results\\binary_classification\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the RandomSearch tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of hyperparameter combinations to try\n",
    "    directory='tuner_results',\n",
    "    project_name='binary_classification'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e66c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the final model with the best hyperparameters\n",
    "final_model = tuner.hypermodel.build(best_hps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab15dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 13s 6ms/step - loss: -4861509120.0000 - accuracy: 0.1123 - val_loss: -23186921472.0000 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: -104669618176.0000 - accuracy: 0.1124 - val_loss: -242031853568.0000 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: -506690502656.0000 - accuracy: 0.1124 - val_loss: -879890530304.0000 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: -1429346451456.0000 - accuracy: 0.1124 - val_loss: -2166843637760.0000 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: -3115012587520.0000 - accuracy: 0.1124 - val_loss: -4364715425792.0000 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: -5841568661504.0000 - accuracy: 0.1124 - val_loss: -7770374930432.0000 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: -9897789882368.0000 - accuracy: 0.1124 - val_loss: -12700700639232.0000 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: -15626665984000.0000 - accuracy: 0.1124 - val_loss: -19520462782464.0000 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: -23387829174272.0000 - accuracy: 0.1124 - val_loss: -28600531156992.0000 - val_accuracy: 0.1135\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: -33594003161088.0000 - accuracy: 0.1124 - val_loss: -40387997597696.0000 - val_accuracy: 0.1135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: -40387997597696.0000 - accuracy: 0.1135\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "# Train the final model\n",
    "final_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the final model\n",
    "test_loss, test_acc = final_model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96df7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
